{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b7257d",
   "metadata": {},
   "source": [
    "# Data Visualization with Plotly Demo\n",
    "\n",
    "## Introduction to Jupyter Notebook\n",
    "Jupyter Notebooks are a staple in any data scientist's toolkit. It is a free, open source, interactive data science environment that can function as both an IDE and a visualisation tool. A Jupyter Notebook is a single document where you can run code, display the output and add equations and explainations. Each notebook is a `.ipynb` file, which is a text file that describes the content of the notebook in JSON format.\n",
    "\n",
    "Each Jupter Notebook contains a kernal that can be thought of as a \"computational engine\" that executes the code within the notebook. Notebooks are made up of a number of cells. For example, this piece of text you are reading resides in the first cell of this notebook. They can be markdown cells that display text in-place or code cells. When a code cell is run, the output is displayed below the cell. The order in which cells are run matters! Cells containing functions or variables have to be run before those same functions or variables can be called from a subsequent cell. \n",
    "\n",
    "How to use a Jupyter Notebook:\n",
    "- To run a cell, either click the arrow to the left of the cell or press `ctrl + Enter` after selecting the cell. When a cell is run, a number will appear in square brackets (e.g. [1]) telling you the order in which each cell is run.\n",
    "- To interrupt a cell while it is running, press the button with the black square in the toolbar at the top\n",
    "- To restart the kernal, right-click `kernel` and choose from the list of restart options available\n",
    "\n",
    "\n",
    "## Introduction to Plotly\n",
    "\n",
    "Pandas is an open source library providing data structure and data analysis tools for the Python language. Plotly is another open source that allows you to put together high quality graphs to faciliate the visualisation of the data. Plotly Dash (written on top of Plotly.js and React.js) allows one to quickly build data apps that are rendered in the browser. \n",
    "\n",
    "This notebook contains examples of how each of these libraries can be leveraged to analyse and visualise data. For more information, please check out the official documentation listed below.\n",
    "\n",
    "#### Further Documentation\n",
    "https://pandas.pydata.org/docs/ \\\n",
    "https://plot.ly/python/ \\\n",
    "https://dash.plotly.com/introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9b749",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "You can install the libraries using pip or conda. \n",
    "\n",
    "**N.B.** you may have to restart the kernel after installing these packages for your first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccdd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/env python\n",
    "\n",
    "# install packages\n",
    "!pip3 install --user pandas\n",
    "!pip3 install --user numpy\n",
    "!pip3 install --user matplotlib\n",
    "!pip3 install --user plotly\n",
    "!pip3 install --user jupyter-dash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d5f13",
   "metadata": {},
   "source": [
    "Having installed the libraries, you can import them as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "\n",
    "#import plotly\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "# Set display row/column to show all data\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e38c6-63e0-4c31-a8ff-f35c5a9b4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user plotly\n",
    "#import plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8adbeb",
   "metadata": {},
   "source": [
    "## Access Data From Endpoint\n",
    "\n",
    "#### Further Documentation\n",
    "https://docs.python-requests.org/en/master/\n",
    "\n",
    "**N.B.** the url used in this example is from the demo project we have set up. Please replace it with your own url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae1c17-4dee-4baf-abff-c07e215d05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190240ef-b0e9-4945-b149-ac040964d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_keyw = []  # list to save the ESG Keywords from file\n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/ESG_Keywords.txt\", \"r\") as file:\n",
    "    esg_keyw=file.read().splitlines()[1:] # splitlines method splits lines into list without new line; excluding header with [1:]\n",
    "    print(esg_keyw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e9bc095d-e2bb-4a32-9d00-557f7196f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "article1 = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article1.txt\", \"r\") as file:\n",
    "    article1=file.read().splitlines() # splitlines method splits lines into list without new line; excluding header with [1:]\n",
    "while(\"\" in article1) :\n",
    "    article1.remove(\"\") # remove empty strings from list of strings 'article1'\n",
    "    \n",
    "    \n",
    "art1_post = []\n",
    "\n",
    "for i in range(len(article1)):\n",
    "    myobj = {key: article1[i]}\n",
    "    x = requests.post(url,  data = myobj)\n",
    "    art1_post.append(x.json())\n",
    "\n",
    "article1g = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article1german.txt\", \"r\") as file:\n",
    "    article1g=file.read().splitlines() # splitlines method splits lines into list without new line\n",
    "while(\"\" in article1g) :\n",
    "    article1g.remove(\"\") # remove empty strings from list of strings 'article1g'\n",
    "    \n",
    "    \n",
    "art1g_post = []\n",
    "\n",
    "for i in range(len(article1g)):\n",
    "    myobj = {key: article1g[i]}\n",
    "    x = requests.post(url,  data = myobj)\n",
    "    art1g_post.append(x.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefc847-cd6e-4534-b8e6-77ab87695124",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://dbgee-mar22-12.ew.r.appspot.com/api/analyze'\n",
    "\n",
    "article2 = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article2.txt\", \"r\") as file:\n",
    "    article2=file.read().splitlines() # splitlines method splits lines into list without new line\n",
    "while(\"\" in article2) :\n",
    "    article2.remove(\"\") # remove empty strings from list of strings 'article2'\n",
    "    \n",
    "art2_post = []\n",
    "\n",
    "for i in range(len(article2)):\n",
    "    myobj = {key: article2[i]}\n",
    "    x = requests.post(url,  data = myobj)\n",
    "    art2_post.append(x.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5eeb964-aad4-4b7d-ac45-338937ad4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://dbgee-mar22-12.ew.r.appspot.com/api/text'\n",
    "url = 'https://dbgee-mar22-12.ew.r.appspot.com/api/analyze'\n",
    "\n",
    "article3 = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article3.txt\", \"r\") as file:\n",
    "    article3=file.read().splitlines() # splitlines method splits lines into list without new line\n",
    "while(\"\" in article3) :\n",
    "    article3.remove(\"\") # remove empty strings from list of strings 'article2'\n",
    "\n",
    "art3_post = []\n",
    "\n",
    "for i in range(len(article3)):\n",
    "    myobj = {key: article3[i]}\n",
    "    x = requests.post(url,  data = myobj)\n",
    "    art3_post.append(x.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14967954-9abb-41d8-88eb-3d17aec955ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "art3_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e94864",
   "metadata": {},
   "source": [
    "## Data Visualisation\n",
    "\n",
    "Plotly is a commonly-used data visualisation library. The following examples will show you how to create different graphs from the sample data.\n",
    "\n",
    "We can first read the sample data into a dataframe. The sample data is taken from the UK Met Office and shows the maximum and minimum temperature, the rainfall and the number of hours of sunlight for each month in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "04d8dae9-620f-4f08-b00e-16f51e4671d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## question 2) Named Entity Extraction ##\n",
    "entity_name=[]\n",
    "entity_type = []\n",
    "entity_score = []\n",
    "entity_sentim = []\n",
    "\n",
    "    #entity_dict.append([dict(zip(dict_keys,i)) for i in result])\n",
    "    # entity_name.append(i[\"name\"] for i in result)\n",
    "entity_lst = []\n",
    "entity_esg = []\n",
    "    \n",
    "for result in art3_post:\n",
    "    for key in result.keys():\n",
    "        entity_lst.append(result.get(key).get('entities'))\n",
    "        entity_esg.append(result.get(key).get('entities_esg'))\n",
    "    \n",
    "# print(len(art3_post))\n",
    "# print(entity_lst)\n",
    "# print(entity_esg)\n",
    "\n",
    "# [i for i in entity_lst]\n",
    "\n",
    "# reduce to 1 a list of lists, flattening :\n",
    "entity_lst_flat = [item for sublist in entity_lst for item in sublist]\n",
    "entity_esg_flat = [item for sublist in entity_esg for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9ae916c2-e700-4795-9664-b848f24510f4",
   "metadata": {},
   "outputs": [
    {
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_esg_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a9181a2-beb5-4204-a021-f710859fafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(entity_lst_flat)\n",
    "for i in range(0,len(entity_lst_flat)):\n",
    "    entity_name.append([i[\"name\"] for i in entity_lst_flat])\n",
    "    entity_type.append([i[\"entitytype\"] for i in entity_lst_flat])\n",
    "    entity_score.append([i[\"score\"] for i in entity_lst_flat])\n",
    "    entity_sentim.append([i[\"sentiment\"] for i in entity_lst_flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "3d8a4fb0-1d46-4d9e-aef2-ab0babe60035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entities that have a ESG match, unique list\n",
    "entity_esg = [i[\"name\"] for i in entity_esg_flat]\n",
    "# list to dataframe\n",
    "entity_esg = pd.DataFrame(list(zip(entity_esg)),  columns = [\"entity\"])\n",
    "# drop duplicates for unique list:\n",
    "entity_esg = entity_esg.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ea735064-bcda-479d-b2c4-cc545924f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 1 a list of lists, flattening :\n",
    "entity_name = [item for sublist in entity_name for item in sublist]\n",
    "entity_type = [item for sublist in entity_type for item in sublist]\n",
    "entity_score = [item for sublist in entity_score for item in sublist]\n",
    "entity_sentim = [item for sublist in entity_sentim for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "61a73c1e-c6da-4c32-a2e3-050c2b355040",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df = pd.DataFrame(list(zip(entity_name, entity_type, entity_score,entity_sentim)),  columns = [\"entity\",\"type\",\"score\",\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2e431207-7f5e-4dab-a8ea-019bfc754252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of duplicates for each entry, reducing df to unique df:\n",
    "entity_df_count = entity_df.groupby(entity_df.columns.tolist(),as_index=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "23853d6a-93bb-4c04-a014-1c78f0c5fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values by score\n",
    "most_scored = entity_df_count.sort_values(by=['score'],  ascending=False)\n",
    "# sort values by # repetitions\n",
    "# entity_df_count.sort_values(by=['size'],  ascending=False)\n",
    "# no many duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc7d6c-c92e-4fd5-aaea-4da642487fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1baab42-c3e3-4765-aa92-1f9b7a45cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df.groupby(['type', 'entity']).size().reset_index(name='obs')\n",
    "#.sort_values(['obs'],ascending=False)\n",
    "#.sort_values(['count'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f988210-0403-4512-b6d3-994ac3fbd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ent_all_stats = entity_df.groupby(['type', 'entity','sentiment']).size().reset_index(name='obs')\n",
    "ent_tot = entity_df.groupby(['type', 'entity']).size().groupby(level=1).max().sort_values(ascending=False).reset_index(name='Frequency')\n",
    "#entity_df.groupby(['entity','sentiment']).size()\n",
    "sentim_tot = entity_df.groupby(['sentiment']).size().reset_index(name='obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0ee4baa5-03f4-4382-8944-47fc4cf83bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment    obs\n",
      "0   neutral  13680\n",
      "1  positive   9424\n",
      "\n",
      "Total Obvs:  23104\n"
     ]
    }
   ],
   "source": [
    "print(sentim_tot)\n",
    "print()\n",
    "print('Total Obvs: ' , sentim_tot['obs'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "557ac8a3-c04b-4349-80f0-e426240090ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Percentage String Function\n",
    "def percentage(part, whole):\n",
    "    percentage = round(100 * float(part)/float(whole),2)\n",
    "    return str(percentage) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f29f8a22-8092-410e-9567-6f09673bfbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Sentiment: 59.21%\n",
      "Positive Sentiment: 40.79%\n",
      "Negative Sentiment: 0%\n"
     ]
    }
   ],
   "source": [
    "if 'neutral' in sentim_tot['sentiment'].values:\n",
    "    print('Neutral Sentiment: ' + percentage(sentim_tot[sentim_tot['sentiment'] == 'neutral']['obs'],sentim_tot['obs'].sum()))\n",
    "else:\n",
    "    print('Neutral Sentiment: 0%')\n",
    "if 'positive' in sentim_tot['sentiment'].values:\n",
    "    print('Positive Sentiment: ' +  percentage(sentim_tot[sentim_tot['sentiment'] == 'positive']['obs'],sentim_tot['obs'].sum()))\n",
    "else:\n",
    "    print('Positive Sentiment: 0%')\n",
    "if 'negative' in sentim_tot['sentiment'].values:\n",
    "    print('Negative Sentiment: ' + percentage(sentim_tot[sentim_tot['sentiment'] == 'negative']['obs'],sentim_tot['obs'].sum()))\n",
    "else:\n",
    "    print('Negative Sentiment: 0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e55c2b-c6c2-40df-9889-7e6da756b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only the entities:\n",
    "entity_name_df = pd.DataFrame(list(zip(entity_name_flat)), columns=[\"entity\"])\n",
    "# descending order by number of repetitions:\n",
    "entity_name_df_sorted = entity_name_df.groupby(entity_name_df.columns.tolist(),as_index=False).size().sort_values(by=['size'],  ascending=False)\n",
    "entity_name_df_sorted.rename(columns = {'entity':'Entity', 'size':'Frequency'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfecf6c-80e3-4c19-8ffb-b67f370c194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only the entities - Ariicle 2:\n",
    "entity_name_flat2 =  [item for sublist in entity_name2 for item in sublist]\n",
    "entity_name_df2 = pd.DataFrame(list(zip(entity_name_flat2)), columns=[\"entity\"])\n",
    "# descending order by number of repetitions:\n",
    "entity_name_df_sorted2 = entity_name_df2.groupby(entity_name_df2.columns.tolist(),as_index=False).size().sort_values(by=['size'],  ascending=False)\n",
    "entity_name_df_sorted2.rename(columns = {'entity':'Entity', 'size':'Frequency'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89ef41-f57c-4f31-a66b-c9b81bae5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity name sorted greater than 1 = more than 1 appearance/repetition\n",
    "ens_gt1 = entity_name_df_sorted[entity_name_df_sorted['Frequency']>1]\n",
    "ens_gt2 = entity_name_df_sorted2[entity_name_df_sorted2['Frequency']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5e4aa703-cabe-4aa8-add1-dfa5b443fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ent_tot\n",
    "ent_tot.rename(columns = {'entity':'Entity'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "21f5cf32-def1-4a0b-916f-a70c7b057f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>227.232323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>216.461847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1520.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency\n",
       "count    99.000000\n",
       "mean    227.232323\n",
       "std     216.461847\n",
       "min     152.000000\n",
       "25%     152.000000\n",
       "50%     152.000000\n",
       "75%     152.000000\n",
       "max    1520.000000"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Stats: Describe 'Frequency' column for Entities\n",
    "ent_tot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "7ef8be49-636c-4169-a247-47fac9e703bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_matches = pd.merge(ent_all_stats, entity_esg, how='inner', on = 'entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "838683c2-b644-4508-87d2-a0b041bea7d2",
   "metadata": {},
   "outputs": [
      ],
      "text/plain": [
       "    type       entity sentiment  obs\n",
       "0  OTHER         Data  positive  304\n",
       "1  OTHER  environment   neutral  152\n",
       "2  OTHER    oversight  positive  152"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esg_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "383bb57b-1f9e-4344-8253-b539fb85b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install plotnine\n",
    "from plotnine import ggplot, aes, geom_line,geom_bar, theme, element_text, ggtitle, geom_text, after_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "6d7a300e-2f2c-4eed-b7d2-c6327c54b176",
   "metadata": {},
   "outputs": [
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Named entity extraction – table of most important/frequently used entities referenced.\n",
    "px.bar(ent_tot, x='Entity', y='Frequency', title= \"Most Frequently used Entities - Article 3\").show()\n",
    "#px.bar(ens_gt2, x='Entity', y='Frequency', title= \"Most Frequently used Entities - Article 2\").show()\n",
    "# gg1 = ggplot(ent_tot, aes(x='Entity', y='Frequency')) + ggtitle(\"Most Frequently used Entities - Article 3\")\n",
    "# print(gg1)\n",
    "print()\n",
    "\n",
    "# Entity All Stats\n",
    "# Entities grouped by Type and Sentiment\n",
    "gg2 = ggplot(ent_all_stats, aes(x='type', y = \"obs\" ,fill = 'sentiment'))+ geom_bar(stat=\"identity\",position=\"dodge\") + theme(axis_text_x=element_text(angle=90)) + ggtitle(\"Entities by Type and Sentiment - Article 3\")\n",
    "print(gg2)\n",
    "print()\n",
    "\n",
    "# Sentiment Analysis\n",
    "gg3 = ggplot(sentim_tot, aes(x='sentiment', y='obs')) + geom_bar(stat=\"identity\",position=\"dodge\") + ggtitle(\"Overall Sentiment - Article 3\")\n",
    "print(gg3)       \n",
    "\n",
    "# ESG Matches\n",
    "gg4 = ggplot(esg_matches, aes(x='entity', y ='obs' ,fill = 'sentiment')) + geom_bar(stat=\"identity\",position=\"dodge\") + ggtitle(\"ESG Keywords Match - Article 3\")\n",
    "print(gg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f840e0b3-3d03-4e72-bfaf-36f7d47236e2",
   "metadata": {},
   "outputs": [
    {
      ],
      "text/plain": [
       "  sentiment    obs\n",
       "0   neutral  13680\n",
       "1  positive   9424"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentim_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca14ef",
   "metadata": {},
   "source": [
    "To gain more insight into a particular column, you can use the *describe()* method on the dataframe column name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb9da5",
   "metadata": {},
   "source": [
    "## Introducing Jupyter Dash\n",
    "\n",
    "Dash is Plotly's open source Python framework for building full stack analytic web applications using pure Python. The JupyterDash library makes these features available from the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31196b12-08cb-4058-9570-85c1502ffda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "# Load Data\n",
    "df = px.data.tips()\n",
    "# Build App\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"JupyterDash Demo\"),\n",
    "    dcc.Graph(id='graph'),\n",
    "    html.Label([\n",
    "        \"colorscale\",\n",
    "        dcc.Dropdown(\n",
    "            id='colorscale-dropdown', clearable=False,\n",
    "            value='plasma', options=[\n",
    "                {'label': c, 'value': c}\n",
    "                for c in px.colors.named_colorscales()\n",
    "            ])\n",
    "    ]),\n",
    "])\n",
    "# Define callback to update graph\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input(\"colorscale-dropdown\", \"value\")]\n",
    ")\n",
    "def update_figure(colorscale):\n",
    "    return px.scatter(\n",
    "        df, x=\"total_bill\", y=\"tip\", color=\"size\",\n",
    "        color_continuous_scale=colorscale,\n",
    "        render_mode=\"webgl\", title=\"Tips\"\n",
    "    )\n",
    "# Run app and display result inline in the notebook\n",
    "app.run_server(mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7f830387",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run ngrok to tunnel Dash app port 8050 to the outside world. \n",
    "### This command runs in the background.\n",
    "get_ipython().system_raw('./ngrok http 8050 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "92ba79d8-bac6-41f2-986e-34fbec4378b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86542e-8c24-49cc-94f6-ddea14de8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7249d9eb-5c22-447f-8e71-0537dc49d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr_options = ent_tot[\"Entity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "58ff448e-1b47-44a8-aeae-ec65e25fb3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash()\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"Sales Funnel Report\"),\n",
    "    html.Div(\n",
    "        [\n",
    "            dcc.Dropdown(\n",
    "                id=\"Entity\",\n",
    "                options=[{\n",
    "                    'label': i,\n",
    "                    'value': i\n",
    "                } for i in mgr_options],\n",
    "                value='All Entities'),\n",
    "        ],\n",
    "        style={'width': '25%',\n",
    "               'display': 'inline-block'}),\n",
    "    dcc.Graph(id='funnel-graph'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75a9ff-11f2-4bb3-a46c-a867922f16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    # dash.dependencies.Output('funnel-graph', 'figure'),\n",
    "    # dash.dependencies.Input('Manager', 'value'))\n",
    "    Output(component_id='funnel-graph', component_property='children'),\n",
    "    Input(component_id='Manager', component_property='value')\n",
    ")\n",
    "def update_output_div(input_value):\n",
    "    return 'Output: {}'.format(input_value)\n",
    "#app.run_server(mode=\"external\", port=8050)\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63687a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ID of the most recent \n",
    "last_text_id = list(ent_tot.keys())[0]\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"JupyterDash Demo\"),\n",
    "    \n",
    "    \n",
    "    # THESE LINES DISPLAY THE OUTPUT OF NLP API\n",
    "    html.P(\"Most Recent Text ID: {}\".format(last_text_id)),\n",
    "    html.P(\"Text Analysed: {}\".format(ent_tot[last_text_id][\"entity\"])),\n",
    "    html.P(\"Sentiment: {}\".format(ent_tot[last_text_id][\"sentiment\"])),\n",
    "  \n",
    "    # THESE LINES DEMO ONE OF THE DASH CORE COMPONENT(dcc) i.e. dcc.Input\n",
    "    html.H3(\"Change the value in the text box to see callbacks in action!\"),\n",
    "    html.Div([\n",
    "        \"Input: \",\n",
    "        dcc.Input(id='my-input', value='initial value', type='text')\n",
    "    ]),\n",
    "    html.Br(),\n",
    "    html.Div(id='my-output'),\n",
    "    \n",
    "    # THESE LINES DEMO THE INTEGRATION OF PLOTLY GRAPHS WITH DASH\n",
    "    dcc.Graph(figure=subplots_fig),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='my-output', component_property='children'),\n",
    "    Input(component_id='my-input', component_property='value')\n",
    ")\n",
    "def update_output_div(input_value):\n",
    "    return 'Output: {}'.format(input_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server(mode=\"external\", port=8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b36aff",
   "metadata": {},
   "source": [
    "#### In case the below cell has errors, please rerun it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc38fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the public URL where you can access the Dash app. Copy this URL.\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45f323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
