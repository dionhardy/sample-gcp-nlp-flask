{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b7257d",
   "metadata": {},
   "source": [
    "# Data Visualization with Plotly Demo\n",
    "\n",
    "## Introduction to Jupyter Notebook\n",
    "Jupyter Notebooks are a staple in any data scientist's toolkit. It is a free, open source, interactive data science environment that can function as both an IDE and a visualisation tool. A Jupyter Notebook is a single document where you can run code, display the output and add equations and explainations. Each notebook is a `.ipynb` file, which is a text file that describes the content of the notebook in JSON format.\n",
    "\n",
    "Each Jupter Notebook contains a kernal that can be thought of as a \"computational engine\" that executes the code within the notebook. Notebooks are made up of a number of cells. For example, this piece of text you are reading resides in the first cell of this notebook. They can be markdown cells that display text in-place or code cells. When a code cell is run, the output is displayed below the cell. The order in which cells are run matters! Cells containing functions or variables have to be run before those same functions or variables can be called from a subsequent cell. \n",
    "\n",
    "How to use a Jupyter Notebook:\n",
    "- To run a cell, either click the arrow to the left of the cell or press `ctrl + Enter` after selecting the cell. When a cell is run, a number will appear in square brackets (e.g. [1]) telling you the order in which each cell is run.\n",
    "- To interrupt a cell while it is running, press the button with the black square in the toolbar at the top\n",
    "- To restart the kernal, right-click `kernel` and choose from the list of restart options available\n",
    "\n",
    "\n",
    "## Introduction to Plotly\n",
    "\n",
    "Pandas is an open source library providing data structure and data analysis tools for the Python language. Plotly is another open source that allows you to put together high quality graphs to faciliate the visualisation of the data. Plotly Dash (written on top of Plotly.js and React.js) allows one to quickly build data apps that are rendered in the browser. \n",
    "\n",
    "This notebook contains examples of how each of these libraries can be leveraged to analyse and visualise data. For more information, please check out the official documentation listed below.\n",
    "\n",
    "#### Further Documentation\n",
    "https://pandas.pydata.org/docs/ \\\n",
    "https://plot.ly/python/ \\\n",
    "https://dash.plotly.com/introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9b749",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "You can install the libraries using pip or conda. \n",
    "\n",
    "**N.B.** you may have to restart the kernel after installing these packages for your first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccdd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/env python\n",
    "\n",
    "# install packages\n",
    "!pip3 install --user pandas\n",
    "!pip3 install --user numpy\n",
    "!pip3 install --user matplotlib\n",
    "!pip3 install --user plotly\n",
    "!pip3 install --user jupyter-dash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d5f13",
   "metadata": {},
   "source": [
    "Having installed the libraries, you can import them as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "\n",
    "#import plotly\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "# Set display row/column to show all data\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e38c6-63e0-4c31-a8ff-f35c5a9b4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user plotly\n",
    "#import plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8adbeb",
   "metadata": {},
   "source": [
    "## Access Data From Endpoint\n",
    "\n",
    "#### Further Documentation\n",
    "https://docs.python-requests.org/en/master/\n",
    "\n",
    "**N.B.** the url used in this example is from the demo project we have set up. Please replace it with your own url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae1c17-4dee-4baf-abff-c07e215d05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0fb55-a992-4cc9-8dd9-07b9ee75e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esg_keyw = []\n",
    "# with open(\"../articles/ESG_Keywords.txt\", \"r\") as file:\n",
    "#     newline_break = \"\"\n",
    "#     for readline in file: \n",
    "#         line_strip = readline.strip()\n",
    "#         esg_keyw.append(line_strip)\n",
    "\n",
    "# print(esg_keyw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190240ef-b0e9-4945-b149-ac040964d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_keyw = []  # list to save the ESG Keywords from file\n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/ESG_Keywords.txt\", \"r\") as file:\n",
    "    esg_keyw=file.read().splitlines()[1:] # splitlines method splits lines into list without new line; excluding header with [1:]\n",
    "    print(esg_keyw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc095d-e2bb-4a32-9d00-557f7196f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "article1 = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article1.txt\", \"r\") as file:\n",
    "    article1=file.read().splitlines() # splitlines method splits lines into list without new line; excluding header with [1:]\n",
    "while(\"\" in article1) :\n",
    "    article1.remove(\"\") # remove empty strings from list of strings 'article1'\n",
    "    \n",
    "print(article1)\n",
    "\n",
    "article1g = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article1german.txt\", \"r\") as file:\n",
    "    article1g=file.read().splitlines() # splitlines method splits lines into list without new line\n",
    "while(\"\" in article1g) :\n",
    "    article1g.remove(\"\") # remove empty strings from list of strings 'article1g'\n",
    "    \n",
    "print(article1g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefc847-cd6e-4534-b8e6-77ab87695124",
   "metadata": {},
   "outputs": [],
   "source": [
    "article2 = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article2.txt\", \"r\") as file:\n",
    "    article2=file.read().splitlines() # splitlines method splits lines into list without new line\n",
    "while(\"\" in article2) :\n",
    "    article2.remove(\"\") # remove empty strings from list of strings 'article2'\n",
    "    \n",
    "print(article2)\n",
    "\n",
    "article3 = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article3.txt\", \"r\") as file:\n",
    "    article3=file.read().splitlines() # splitlines method splits lines into list without new line\n",
    "while(\"\" in article3) :\n",
    "    article3.remove(\"\") # remove empty strings from list of strings 'article2'\n",
    "    \n",
    "print(article3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5eeb964-aad4-4b7d-ac45-338937ad4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://dbgee-mar22-12.ew.r.appspot.com/api/text'\n",
    "url = 'https://dbgee-mar22-12.ew.r.appspot.com/api/analyze'\n",
    "\n",
    "article3 = []  \n",
    "# https://www.delftstack.com/howto/python/python-readlines-without-newline/\n",
    "with open(\"articles/article3.txt\", \"r\") as file:\n",
    "    article3=file.read().splitlines() # splitlines method splits lines into list without new line\n",
    "while(\"\" in article3) :\n",
    "    article3.remove(\"\") # remove empty strings from list of strings 'article2'\n",
    "\n",
    "art3_post = []\n",
    "\n",
    "for i in range(len(article3)):\n",
    "    myobj = {key: article3[i]}\n",
    "    x = requests.post(url,  data = myobj)\n",
    "    art3_post.append(x.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14967954-9abb-41d8-88eb-3d17aec955ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "art3_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c61d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define endpoint url\n",
    "url = \"https://dbgee-mar22-12.ew.r.appspot.com/api/text\"\n",
    "\n",
    "# use requests library to send HTTP requests\n",
    "# in this example, GET sentiment analysis data\n",
    "data = json.loads(requests.get(url).text)\n",
    "\n",
    "# examine data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56021fe8-5968-4d29-a5b1-98c138738153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# url = \"https://dbgee-mar22-12.ew.r.appspot.com/api/text\"\n",
    "\n",
    "# # data = {\"eventType\": \"AAS_PORTAL_START\", \"data\": {\"uid\": \"hfe3hf45huf33545\", \"aid\": \"1\", \"vid\": \"1\"}}\n",
    "# # params = {'sessionKey': '9ebbd0b25760557393a43064a92bae539d962103', 'format': 'xml', 'platformId': 1}\n",
    "\n",
    "# requests.post(url, params=article2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4289a-f0d9-43bf-b0ca-53b7380ad007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esg_keyw\n",
    "\n",
    "filterEsgWords = open('articles/ESG_Keywords.txt', \"r\").readlines()\n",
    "words = [w.lower().strip() for w in filterEsgWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fe93d-32ac-4e61-8c8e-975cef4bc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_keyw_low = [w.lower() for w in esg_keyw]\n",
    "#words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2ccee-a81d-4fee-b511-6a02bdb507bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = [\n",
    "]\n",
    " \n",
    "#Adding dictionary (entity characteristics) to the list:\n",
    "#entity_list.append({'name':48,'type':'other', 'score':28})\n",
    " \n",
    "print(entity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e94864",
   "metadata": {},
   "source": [
    "## Data Visualisation\n",
    "\n",
    "Plotly is a commonly-used data visualisation library. The following examples will show you how to create different graphs from the sample data.\n",
    "\n",
    "We can first read the sample data into a dataframe. The sample data is taken from the UK Met Office and shows the maximum and minimum temperature, the rainfall and the number of hours of sunlight for each month in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7b071-f467-484a-adee-8bbb2183e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "\n",
    "def sample_analyze_entities(text_content):\n",
    "    \"\"\"\n",
    "    Analyzing Entities in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'California is a state.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = language_v1.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_entities(request = {'document': document, 'encoding_type': encoding_type})\n",
    "    \n",
    "    # TODO add in the filter file here\n",
    "    entity_list = []\n",
    "    # Loop through entitites returned from the API\n",
    "    for entity in response.entities:\n",
    "        #entity_list.append([entity.name,entity.type_, entity.salience])\n",
    "        entity_list.append({'name':entity.name, 'type':entity.type_, 'score':entity.salience})\n",
    "        \n",
    "       # print(u\"Representative name for the entity: {}\".format(entity.name))\n",
    "\n",
    "        if (entity.name.lower() in words):\n",
    "            print(\"We got a match \" + entity.name.lower())\n",
    "\n",
    "            \n",
    "    return(entity_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8dae9-620f-4f08-b00e-16f51e4671d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## question 2) Named Entity Extraction ##\n",
    "entity_name=[]\n",
    "entity_type = []\n",
    "entity_score = []\n",
    "\n",
    "for x in range(1,len(article1)):\n",
    "    result = sample_analyze_entities(article1[x])\n",
    "    #entity_dict.append([dict(zip(dict_keys,i)) for i in result])\n",
    "    \n",
    "    entity_name.append(i[\"name\"] for i in result)\n",
    "    entity_type.append(i[\"type\"] for i in result)\n",
    "    entity_score.append([i[\"score\"] for i in result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71baca-31c2-40ed-bf63-c2c8f196d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## question 2) Named Entity Extraction ##\n",
    "entity_name2=[]\n",
    "entity_type2 = []\n",
    "entity_score2 = []\n",
    "\n",
    "for x in range(1,len(article2)):\n",
    "    result = sample_analyze_entities(article2[x])\n",
    "    #entity_dict.append([dict(zip(dict_keys,i)) for i in result])\n",
    "    \n",
    "    entity_name2.append(i[\"name\"] for i in result)\n",
    "    entity_type2.append(i[\"type\"] for i in result)\n",
    "    entity_score2.append([i[\"score\"] for i in result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc8d80-c7fa-4a93-9511-b77f6702e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 1 a list of lists:\n",
    "entity_name_flat = [item for sublist in entity_name for item in sublist]\n",
    "entity_type_flat = [item for sublist in entity_type for item in sublist]\n",
    "entity_score_flat = [item for sublist in entity_score for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a73c1e-c6da-4c32-a2e3-050c2b355040",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df = pd.DataFrame(list(zip(entity_name_flat, entity_type_flat, entity_score_flat)),  columns = [\"entity\",\"type\",\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e431207-7f5e-4dab-a8ea-019bfc754252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of duplicates for each entry, reducing df to unique df:\n",
    "entity_df_count = entity_df.groupby(entity_df.columns.tolist(),as_index=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23853d6a-93bb-4c04-a014-1c78f0c5fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values by score\n",
    "most_scored = entity_df_count.sort_values(by=['score'],  ascending=False)\n",
    "# sort values by # repetitions\n",
    "# entity_df_count.sort_values(by=['size'],  ascending=False)\n",
    "# no many duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e55c2b-c6c2-40df-9889-7e6da756b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only the entities:\n",
    "entity_name_df = pd.DataFrame(list(zip(entity_name_flat)), columns=[\"entity\"])\n",
    "# descending order by number of repetitions:\n",
    "entity_name_df_sorted = entity_name_df.groupby(entity_name_df.columns.tolist(),as_index=False).size().sort_values(by=['size'],  ascending=False)\n",
    "entity_name_df_sorted.rename(columns = {'entity':'Entity', 'size':'Frequency'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfecf6c-80e3-4c19-8ffb-b67f370c194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only the entities - Ariicle 2:\n",
    "entity_name_flat2 =  [item for sublist in entity_name2 for item in sublist]\n",
    "entity_name_df2 = pd.DataFrame(list(zip(entity_name_flat2)), columns=[\"entity\"])\n",
    "# descending order by number of repetitions:\n",
    "entity_name_df_sorted2 = entity_name_df2.groupby(entity_name_df2.columns.tolist(),as_index=False).size().sort_values(by=['size'],  ascending=False)\n",
    "entity_name_df_sorted2.rename(columns = {'entity':'Entity', 'size':'Frequency'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89ef41-f57c-4f31-a66b-c9b81bae5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity name sorted greater than 1 = more than 1 appearance/repetition\n",
    "ens_gt1 = entity_name_df_sorted[entity_name_df_sorted['Frequency']>1]\n",
    "ens_gt2 = entity_name_df_sorted2[entity_name_df_sorted2['Frequency']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a300e-2f2c-4eed-b7d2-c6327c54b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named entity extraction â€“ table of most important/frequently used entities referenced.\n",
    "px.bar(ens_gt1, x='Entity', y='Frequency', title= \"Most Frequently used Entities - Article 1\").show()\n",
    "px.bar(ens_gt2, x='Entity', y='Frequency', title= \"Most Frequently used Entities - Article 2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca14ef",
   "metadata": {},
   "source": [
    "To gain more insight into a particular column, you can use the *describe()* method on the dataframe column name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb9da5",
   "metadata": {},
   "source": [
    "## Introducing Jupyter Dash\n",
    "\n",
    "Dash is Plotly's open source Python framework for building full stack analytic web applications using pure Python. The JupyterDash library makes these features available from the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f830387",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run ngrok to tunnel Dash app port 8050 to the outside world. \n",
    "### This command runs in the background.\n",
    "get_ipython().system_raw('./ngrok http 8050 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63687a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ID of the most recent \n",
    "last_text_id = list(data.keys())[0]\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"JupyterDash Demo\"),\n",
    "    \n",
    "    \n",
    "    # THESE LINES DISPLAY THE OUTPUT OF NLP API\n",
    "    html.P(\"Most Recent Text ID: {}\".format(last_text_id)),\n",
    "    html.P(\"Text Analysed: {}\".format(data[last_text_id][\"text\"])),\n",
    "    html.P(\"Sentiment: {}\".format(data[last_text_id][\"sentiment\"])),\n",
    "  \n",
    "    # THESE LINES DEMO ONE OF THE DASH CORE COMPONENT(dcc) i.e. dcc.Input\n",
    "    html.H3(\"Change the value in the text box to see callbacks in action!\"),\n",
    "    html.Div([\n",
    "        \"Input: \",\n",
    "        dcc.Input(id='my-input', value='initial value', type='text')\n",
    "    ]),\n",
    "    html.Br(),\n",
    "    html.Div(id='my-output'),\n",
    "    \n",
    "    # THESE LINES DEMO THE INTEGRATION OF PLOTLY GRAPHS WITH DASH\n",
    "    dcc.Graph(figure=subplots_fig),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='my-output', component_property='children'),\n",
    "    Input(component_id='my-input', component_property='value')\n",
    ")\n",
    "def update_output_div(input_value):\n",
    "    return 'Output: {}'.format(input_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server(mode=\"external\", port=8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b36aff",
   "metadata": {},
   "source": [
    "#### In case the below cell has errors, please rerun it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc38fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the public URL where you can access the Dash app. Copy this URL.\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45f323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
